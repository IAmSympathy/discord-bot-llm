import {ChannelType, ChatInputCommandInteraction, Client, DMChannel, Message as DiscordMessage, TextChannel, ThreadChannel} from "discord.js";
import {FileMemory} from "../memory/fileMemory";
import {analyzeMessageType} from "../memory/memoryFilter";
import {DISCORD_TYPING_UPDATE_INTERVAL, MEMORY_FILE_PATH, MEMORY_MAX_TURNS} from "../utils/constants";
import {ImageAnalysisResult, processImagesWithMetadata} from "../services/imageService";
import {getWebContext} from "../services/searchService";
import {OllamaService} from "../services/ollamaService";
import {DiscordMessageManager, ImageAnalysisAnimation} from "./discordMessageManager";
import {EmojiReactionHandler} from "./emojiReactionHandler";
import {buildCurrentUserBlock, buildHistoryBlock, buildThreadStarterBlock, buildWebContextBlock} from "./promptBuilder";
import {UserProfileService} from "../services/userProfileService";
import {logBotImageAnalysis, logBotResponse, logBotWebSearch, logError} from "../utils/discordLogger";
import {BotStatus, clearStatus, setStatus} from "../services/statusService";
import {getDMRecentTurns} from "../services/dmMemoryService";
import {createLogger} from "../utils/logger";
import {NETRICSA_USER_ID, NETRICSA_USERNAME, recordNetricsaWebSearch} from "../services/userStatsService";
import {recordAIConversationStats} from "../services/statsRecorder";

const wait = require("node:timers/promises").setTimeout;
const logger = createLogger("Queue");

interface DirectLLMRequest {
    prompt: string;
    userId: string;
    userName: string;
    channel: TextChannel | ThreadChannel | DMChannel;
    client: Client;
    replyToMessage?: DiscordMessage;
    referencedMessage?: DiscordMessage;
    imageUrls?: string[];
    sendMessage?: boolean;
    threadStarterContext?: {
        content: string;
        author: string;
        imageUrls: string[];
    };
    skipImageAnalysis?: boolean; // Flag pour indiquer que les images sont d√©j√† analys√©es
    preAnalyzedImages?: ImageAnalysisResult[]; // R√©sultats d'analyse pr√©-calcul√©s
    originalUserMessage?: string; // Message original de l'utilisateur (pour les logs, sans les instructions syst√®me)
    preStartedAnimation?: ImageAnalysisAnimation; // Animation d√©j√† d√©marr√©e √† r√©utiliser
    skipMemory?: boolean; // Flag pour ne pas enregistrer dans la m√©moire (ex: messages de bienvenue)
    returnResponse?: boolean; // Flag pour retourner le contenu final g√©n√©r√©
    interaction?: ChatInputCommandInteraction; // Interaction optionnelle pour les messages √©ph√©m√®res
    progressMessage?: any; // Message d'animation d√©j√† cr√©√© (comme /imagine) √† r√©utiliser pour la r√©ponse
}

// Configuration m√©moire persistante
const memory = new FileMemory(MEMORY_FILE_PATH);
const ollamaService = new OllamaService();

// ===== QUEUE GLOBALE UNIQUE =====
// Avec un seul LLM, toutes les requ√™tes (DM + Serveur) doivent √™tre trait√©es s√©quentiellement
type AsyncJob<T> = () => Promise<T>;
let globalQueue: Promise<unknown> = Promise.resolve();
const activeStreams = new Map<string, { abortFlag: boolean; channelId: string; userId: string }>();
const activeImageAnalysis = new Map<string, ImageAnalysisAnimation & { userId: string }>(); // Animations d'analyse d'image actives
const pendingResponses = new Map<string, { resolve: (value: string) => void; reject: (error: any) => void }>(); // Pour stocker les promesses de r√©ponse
const usersInQueue = new Set<string>(); // Utilisateurs actuellement dans la queue

// NOUVEAU : Cache des derni√®res questions par canal pour le contexte conversationnel
// Permet de garder les "Oui"/"Non" qui r√©pondent √† des questions importantes
interface RecentQuestion {
    timestamp: number;
    userId: string;
    userName: string;
    question: string;
}

const recentQuestionsByChannel = new Map<string, RecentQuestion>();
const QUESTION_CONTEXT_TIMEOUT = 30000; // 30 secondes

/**
 * Filtre les liens GIF (Tenor, Discord CDN et GIF directs) d'un message
 * @param messageContent Le contenu du message √† filtrer
 * @returns Le message sans les liens GIF
 */
export function removeGifLinks(messageContent: string): string {
    let cleanedContent = messageContent;

    // Supprimer les liens Tenor
    const tenorRegex = /https?:\/\/(?:media\.tenor\.com|tenor\.com|c\.tenor\.com)\/[^\s]+/gi;
    cleanedContent = cleanedContent.replace(tenorRegex, '');

    // Supprimer les liens GIF directs (incluant Discord CDN avec param√®tres)
    const gifRegex = /https?:\/\/[^\s]+\.gif(?:\?[^\s]*)?/gi;
    cleanedContent = cleanedContent.replace(gifRegex, '');

    // Nettoyer les espaces multiples et trim
    cleanedContent = cleanedContent.replace(/\s+/g, ' ').trim();

    return cleanedContent;
}

/**
 * Mettre une t√¢che en queue globale unique
 * Garantit que toutes les requ√™tes LLM (DM + Serveur) sont trait√©es s√©quentiellement
 */
export function enqueueGlobally<T>(job: AsyncJob<T>): Promise<T> {
    const prev = globalQueue;

    const next = prev
        .catch(() => {
            // Avaler les erreurs du job pr√©c√©dent pour ne pas bloquer la file
        })
        .then(job);

    globalQueue = next.catch(() => {
        // Capturer les erreurs pour ne pas casser la cha√Æne
    });

    return next;
}


// Fonction pour effacer TOUTE la m√©moire globale
export async function clearAllMemory(): Promise<void> {
    await memory.clearAll();
    logger.info(`Global memory cleared (all channels)`);
}

// Fonction pour arr√™ter un stream en cours
export function abortStream(channelKey: string, requestingUserId?: string, isAdminOrOwner: boolean = false): boolean {
    const streamInfo = activeStreams.get(channelKey);
    if (streamInfo) {
        // V√©rifier si l'utilisateur a le droit d'arr√™ter ce stream
        if (!isAdminOrOwner && requestingUserId && streamInfo.userId !== requestingUserId) {
            return false; // Pas autoris√©
        }

        streamInfo.abortFlag = true;
        activeStreams.delete(channelKey);
        logger.info(`Stream aborted for channel ${channelKey}`);
        return true;
    }
    return false;
}

// Fonction pour enregistrer une animation d'analyse d'image
export function registerImageAnalysis(channelKey: string, animation: ImageAnalysisAnimation, userId: string): void {
    const animationWithUserId = Object.assign({}, animation, {userId});
    activeImageAnalysis.set(channelKey, animationWithUserId);
}

// Fonction pour arr√™ter une analyse d'image en cours
export async function abortImageAnalysis(channelKey: string, requestingUserId?: string, isAdminOrOwner: boolean = false): Promise<boolean> {
    const animation = activeImageAnalysis.get(channelKey);
    if (animation) {
        // V√©rifier si l'utilisateur a le droit d'arr√™ter cette analyse
        if (!isAdminOrOwner && requestingUserId && animation.userId !== requestingUserId) {
            return false; // Pas autoris√©
        }

        await animation.stop();
        activeImageAnalysis.delete(channelKey);
        logger.info(`Image analysis aborted for channel ${channelKey}`);
        return true;
    }
    return false;
}

// Fonction pour nettoyer une animation d'analyse termin√©e
export function cleanupImageAnalysis(channelKey: string): void {
    activeImageAnalysis.delete(channelKey);
}

// Fonction pour traiter une requ√™te LLM directement (sans thread, pour le watch de channel)
export async function processLLMRequest(request: DirectLLMRequest): Promise<string | void> {
    const {prompt, userId, userName, channel, client, replyToMessage, imageUrls, sendMessage = true, threadStarterContext, skipImageAnalysis = false, preAnalyzedImages = [], originalUserMessage, preStartedAnimation, skipMemory = false, returnResponse = false, interaction} = request;

    // V√©rifier si l'utilisateur est d√©j√† dans la queue
    if (usersInQueue.has(userId)) {
        logger.info(`User ${userId} (${userName}) tried to add another request while already in queue`);

        // Supprimer le message de l'utilisateur s'il existe
        if (replyToMessage && replyToMessage.deletable) {
            await replyToMessage.delete().catch((err) => logger.error("Failed to delete duplicate message:", err));
        }

        // Envoyer un message √©ph√©m√®re
        if (channel.type !== ChannelType.DM) {
            try {
                // Si on a une interaction, utiliser followUp √©ph√©m√®re
                if (interaction) {
                    await interaction.followUp({
                        content: `Tu es d√©j√† dans la file d'attente. Attends que ta requ√™te actuelle soit termin√©e.`,
                        ephemeral: true
                    });
                } else {
                    // Sinon, envoyer un message normal et le supprimer apr√®s 5 secondes
                    const warningMessage = await channel.send({
                        content: `> ‚åõ Tu es d√©j√† dans la file d'attente. Attends que ta requ√™te actuelle soit termin√©e.`,
                    });
                    setTimeout(() => {
                        warningMessage.delete().catch(() => {
                        });
                    }, 5000);
                }
            } catch (err) {
                logger.error("Failed to send queue warning:", err);
            }
        }
        return;
    }

    // Ajouter l'utilisateur √† la queue
    usersInQueue.add(userId);
    logger.info(`User ${userId} added to queue. Current queue size: ${usersInQueue.size}`);

    // Cl√© de m√©moire unique par channel
    // Si on est dans le watched channel, utiliser son ID fixe
    // Sinon, utiliser l'ID du channel actuel (pour les mentions dans d'autres channels)
    const watchedChannelId = process.env.WATCH_CHANNEL_ID;
    const channelKey = channel.id === watchedChannelId ? watchedChannelId : channel.id;

    // Si returnResponse est demand√©, cr√©er une promesse pour attendre le r√©sultat
    let responsePromise: Promise<string> | undefined;
    if (returnResponse) {
        responsePromise = new Promise<string>((resolve, reject) => {
            pendingResponses.set(channelKey, {resolve, reject});
        });
    }

    let currentStatusId: string = "";

    // Mettre en queue globale unique (un seul LLM pour toutes les requ√™tes)
    enqueueGlobally(async () => {
        const requestStartTime = Date.now();
        logger.info(`Processing request from user ${userId} in ${channel.type === ChannelType.DM ? 'DM' : `#${(channel as any).name || channelKey}`}`);
        logger.info(`User ${userId} sent prompt: ${prompt}${imageUrls && imageUrls.length > 0 ? ` with ${imageUrls.length} image(s)` : ""}`);


        // Enregistrer ce stream comme actif
        const streamInfo = {abortFlag: false, channelId: channel.id, userId};
        activeStreams.set(channelKey, streamInfo);

        // Changer le statut selon l'activit√©
        if (imageUrls && imageUrls.length > 0 && !skipImageAnalysis) {
            await setStatus(client, imageUrls.length === 1 ? BotStatus.ANALYZING_IMAGE : BotStatus.ANALYZING_IMAGES(imageUrls.length), 60000); // Statut sp√©cifique pour l'analyse d'images, dur√©e plus longue
        }

        // G√©rer l'animation d'analyse d'image (seulement si pas d√©j√† analys√©e et pas skip)
        // Si une animation a d√©j√† √©t√© d√©marr√©e (par forumThreadHandler), la r√©utiliser
        const analysisAnimation = preStartedAnimation || new ImageAnalysisAnimation();
        if (imageUrls && imageUrls.length > 0 && !skipImageAnalysis && !preStartedAnimation) {
            await analysisAnimation.start(replyToMessage, channel, interaction);
        }

        // Traiter les images avec m√©tadonn√©es compl√®tes
        let imageResults: ImageAnalysisResult[] = [];
        let imageDescriptions: string[] = [];

        if (imageUrls && imageUrls.length > 0) {
            try {
                // Si les images sont d√©j√† analys√©es (depuis forumThreadHandler), utiliser les r√©sultats
                if (skipImageAnalysis && preAnalyzedImages && preAnalyzedImages.length > 0) {
                    logger.info(`Using pre-analyzed images (${preAnalyzedImages.length})`);
                    imageResults = preAnalyzedImages;
                    imageDescriptions = imageResults.map(r => r.description);
                    // Ne pas logger ici, d√©j√† logg√© dans forumThreadHandler
                } else if (skipImageAnalysis) {
                    // Skip compl√®tement l'analyse d'images si le flag est true (ex: !s dans le message)
                    logger.info(`Skipping image analysis for ${imageUrls.length} image(s) (!s flag)`);
                    imageDescriptions = imageUrls.map((url, index) => `[Image ${index + 1} - analyse d√©sactiv√©e par l'utilisateur]`);
                } else {
                    // Sinon, analyser les images normalement
                    imageResults = await processImagesWithMetadata(imageUrls);
                    imageDescriptions = imageResults.map(r => r.description);

                    // Logger l'analyse d'images avec toutes les m√©tadonn√©es
                    if (imageResults.length > 0) {
                        await logBotImageAnalysis(userName, imageResults);
                    }
                }
            } catch (imageError) {
                logger.error("Error during image analysis:", imageError);
                // En cas d'erreur (timeout, etc.), cr√©er des descriptions fallback
                imageDescriptions = imageUrls.map((url, index) => `[Image ${index + 1} - erreur lors de l'analyse]`);
            } finally {
                // Arr√™ter l'animation d'analyse d'image dans tous les cas (succ√®s ou erreur)
                await analysisAnimation.stop();
                logger.info("Image analysis animation stopped");
                // NE PAS supprimer le message - il sera r√©utilis√© par le messageManager
            }
        }

        // Traiter les images du thread starter si pr√©sent
        let threadStarterImageDescriptions: string[] = [];
        if (threadStarterContext && threadStarterContext.imageUrls.length > 0) {
            logger.info(`Processing ${threadStarterContext.imageUrls.length} image(s) from thread starter`);
            const threadImageResults = await processImagesWithMetadata(threadStarterContext.imageUrls);
            threadStarterImageDescriptions = threadImageResults.map(r => r.description);

            if (threadImageResults.length > 0) {
                await logBotImageAnalysis(`${userName} (thread starter)`, threadImageResults);
            }
        }

        // D√©terminer si c'est un DM
        const isDM = channel.type === ChannelType.DM;

        // Charger les prompts syst√®me avec le contexte appropri√© (DM ou serveur)
        const {finalPrompt: finalSystemPrompt} = ollamaService.loadSystemPrompts(channel.id, isDM);

        // Charger la m√©moire appropri√©e (sauf si skipMemory est activ√©)
        let recentTurns: any[];

        if (skipMemory) {
            // Ne pas charger de m√©moire
            recentTurns = [];
            logger.info(`Memory skipped (skipMemory flag)`);
        } else if (isDM) {
            // Charger la m√©moire DM de l'utilisateur
            recentTurns = await getDMRecentTurns(userId, MEMORY_MAX_TURNS);
            logger.info(`${recentTurns.length} DM turns loaded for ${userName}`);
        } else {
            // Charger l'historique de m√©moire GLOBAL avec Sliding Window
            recentTurns = await memory.getRecentTurns(MEMORY_MAX_TURNS);
            logger.info(`${recentTurns.length} turns loaded (Sliding Window active)`);
        }

        // Obtenir le contexte web si n√©cessaire
        const webSearchStartTime = Date.now();

        // D√©tecter si une recherche web est n√©cessaire
        const needsWebSearch = prompt.toLowerCase().includes("recherche") ||
            prompt.toLowerCase().includes("google") ||
            prompt.toLowerCase().includes("cherche") ||
            prompt.includes("?");

        const webContext = await getWebContext(prompt);
        if (webContext) {
            const webSearchTime = Date.now() - webSearchStartTime;
            logger.info(`Web context added to prompt (${webSearchTime}ms)`);

            // Logger la recherche web avec le temps
            await logBotWebSearch(userName, prompt, webContext.facts?.length || 0, webSearchTime);

            // Enregistrer la recherche web uniquement pour Netricsa elle-m√™me
            recordNetricsaWebSearch();

            // Tracker la recherche web pour la mission imposteur
            const {trackImpostorWebSearch} = require("../services/events/impostorMissionTracker");
            await trackImpostorWebSearch(client, userId);
        }

        // R√©cup√©rer le profil de l'utilisateur actuel
        const userProfileSummary = UserProfileService.getProfileSummary(userId);
        let userProfileBlock = "";
        if (userProfileSummary) {
            userProfileBlock = `\n\n‚ïê‚ïê‚ïê PROFIL DE L'UTILISATEUR ACTUEL: ${userName.toUpperCase()} (UID Discord: ${userId}) ‚ïê‚ïê‚ïê\n‚ö†Ô∏è Ce profil appartient √† la personne qui t'envoie le message actuel.\n${userProfileSummary}\n‚ïê‚ïê‚ïê FIN DU PROFIL DE ${userName.toUpperCase()} ‚ïê‚ïê‚ïê`;
            logger.info(`Profile loaded for ${userName}`);
        }

        // Obtenir le nom du channel actuel (ou "DM avec {userName}" si c'est un DM)
        const channelName = isDM
            ? `DM avec ${userName}`
            : ((channel as any).name || `channel-${channel.id}`);

        // Construire les blocs de prompt
        const threadStarterBlock = threadStarterContext ? buildThreadStarterBlock(threadStarterContext, threadStarterImageDescriptions) : "";
        const historyBlock = buildHistoryBlock(recentTurns, channel.id);
        const webBlock = buildWebContextBlock(webContext);
        const currentUserBlock = buildCurrentUserBlock(userId, userName, prompt, imageDescriptions, recentTurns);

        // Assembler les messages pour l'API
        // Le thread starter va EN PREMIER, avant l'historique
        // Le profil utilisateur vient apr√®s le reste
        const messages = [
            {
                role: "system" as const,
                content: `${finalSystemPrompt}${userProfileBlock}\n\n${threadStarterBlock}${webBlock}${historyBlock.length > 0 ? `\n\n${historyBlock}` : ""}`,
            },
            {
                role: "user" as const,
                content: currentUserBlock,
            },
        ];

        if (imageDescriptions.length > 0) {
            logger.info(`${imageDescriptions.length} image description(s) included in context`);
        }

        // Changer le statut √† "√©crit"
        await setStatus(client, BotStatus.WRITING);

        // D√©marrer l'indicateur "est en train d'√©crire" de Discord
        let typingInterval: NodeJS.Timeout | null = null;
        try {
            // Envoyer l'indicateur imm√©diatement
            await channel.sendTyping();
            // Renouveler toutes les 5 secondes (l'indicateur expire apr√®s 10 secondes)
            typingInterval = setInterval(async () => {
                try {
                    await channel.sendTyping();
                } catch (error) {
                    // Ignorer les erreurs (canal supprim√©, etc.)
                }
            }, 5000);
        } catch (error) {
            logger.warn("Could not send typing indicator:", error);
        }

        logger.info(`Sending request to Ollama`);

        let loadingTimeout: NodeJS.Timeout | null = null; // D√©clarer ici pour acc√®s dans catch

        try {
            // TWO-STEP APPROACH :
            // 1. Premi√®re requ√™te : G√©n√©rer la r√©ponse SANS tools (pour garantir une r√©ponse textuelle)
            // 2. Deuxi√®me requ√™te : Analyser avec tools en arri√®re-plan pour extraire les infos
            const response = await ollamaService.chat(messages, {}, true, undefined); // Pas de tools pour la premi√®re requ√™te
            const reader = response.body?.getReader();
            const decoder = new TextDecoder();
            let result = "";

            // Gestionnaires
            const messageManager = new DiscordMessageManager(channel, replyToMessage, interaction);
            // Toujours passer l'animation au messageManager
            // - Si l'animation a √©t√© utilis√©e pour l'analyse d'images, elle sera r√©utilis√©e pour le premier message
            // - Si c'est une interaction, l'animation n'a pas √©t√© cr√©√©e (skip) donc pas de r√©utilisation
            messageManager.setAnalysisAnimation(analysisAnimation);

            // Configurer le callback pour arr√™ter le typing indicator d√®s le premier message envoy√©
            messageManager.setOnFirstMessageSent(() => {
                if (typingInterval) {
                    clearInterval(typingInterval);
                    typingInterval = null;
                    logger.info("Typing indicator stopped (first message sent)");
                }
            });

            const emojiHandler = new EmojiReactionHandler(replyToMessage);

            let jsonBuffer = "";
            let promptTokens = 0;
            let completionTokens = 0;
            let totalTokens = 0;
            let toolCalls: any[] = []; // Stocker les tool calls (pour la 2e requ√™te)
            let firstChunkReceived = false; // Flag pour d√©tecter le premier chunk
            let loadingMessageSent = false; // Flag pour le message de chargement

            // Timeout pour d√©tecter si le mod√®le met trop de temps √† r√©pondre (rechargement)
            loadingTimeout = setTimeout(async () => {
                if (!firstChunkReceived && !loadingMessageSent && sendMessage) {
                    loadingMessageSent = true;
                    logger.info("Model loading detected (5s without first chunk), sending loading message...");
                    try {
                        const loadingMsg = await channel.send("‚è≥ Chargement du mod√®le en cours...");
                        // Supprimer le message une fois que le mod√®le r√©pond
                        setTimeout(() => {
                            loadingMsg.delete().catch(() => {
                            });
                        }, 30000); // Supprimer apr√®s 30s max
                    } catch (err) {
                        logger.warn("Could not send loading message:", err);
                    }
                }
            }, 5000); // Attendre 5 secondes avant d'afficher le message

            // Pour les interactions, on d√©sactive le throttling (on enverra tout d'un coup √† la fin)
            // Pour les messages normaux, on garde le throttling pour la mise √† jour en temps r√©el
            let throttleResponseInterval: NodeJS.Timeout | null = null;
            if (!interaction) {
                throttleResponseInterval = setInterval(() => {
                    if (sendMessage) {
                        messageManager.throttleUpdate().catch((err) => logger.error("[Throttle] Update error:", err));
                    }
                }, DISCORD_TYPING_UPDATE_INTERVAL);
            } else {
                logger.info("Interaction detected - streaming disabled, will send complete message at the end");
            }


            return new ReadableStream({
                start(controller) {
                    return pump();

                    function pump(): any {
                        return reader?.read().then(async function ({done, value}) {
                            if (streamInfo.abortFlag) {
                                logger.info(`Stream aborted by user for channel ${channelKey}`);
                                if (throttleResponseInterval) clearInterval(throttleResponseInterval);
                                if (typingInterval) clearInterval(typingInterval);
                                await analysisAnimation.stop();
                                activeStreams.delete(channelKey);

                                // Retirer l'utilisateur de la queue lors de l'annulation
                                usersInQueue.delete(userId);
                                logger.info(`User ${userId} removed from queue (aborted). Current queue size: ${usersInQueue.size}`);

                                controller.close();
                                return;
                            }

                            if (done) {
                                logger.info(`Request complete for user ${userId}`);

                                // Nettoyer le timeout de chargement
                                if (loadingTimeout) clearTimeout(loadingTimeout);

                                if (totalTokens > 0) {
                                    logger.info(`Tokens - Prompt: ${promptTokens} | Completion: ${completionTokens} | Total: ${totalTokens}`);
                                }

                                await wait(2000);

                                // Pour les interactions, envoyer le message complet d'un coup
                                if (interaction && sendMessage) {
                                    logger.info("Sending complete message for interaction (no streaming)");
                                    messageManager.addToCurrentChunk(result);
                                    await messageManager.throttleUpdate(true); // Force=true pour envoyer m√™me si < 20 chars
                                } else if (sendMessage) {
                                    // Pour les messages normaux, finaliser ou cr√©er le message
                                    if (messageManager.hasMessages()) {
                                        // Des messages ont √©t√© cr√©√©s pendant le streaming, les finaliser
                                        await messageManager.finalizeLastMessage();
                                    } else {
                                        // Aucun message cr√©√© (r√©ponse courte < 20 chars), cr√©er maintenant
                                        logger.info("No messages created during streaming, creating final message now");
                                        const cleanedResult = await emojiHandler.extractAndApply(result);
                                        messageManager.addToCurrentChunk(cleanedResult);
                                        await messageManager.throttleUpdate(true); // Force=true pour envoyer m√™me si < 20 chars
                                    }
                                }

                                // Nettoyer et sauvegarder
                                const cleanedText = await emojiHandler.extractAndApply(result);
                                const isModerationRefusal =
                                    cleanedText.toLowerCase().includes("je suis d√©sol√©e") ||
                                    cleanedText.toLowerCase().includes("je ne peux pas r√©pondre") ||
                                    cleanedText.toLowerCase().includes("je ne r√©pondrai pas");

                                // V√©rifier qu'il y a du texte en plus de l'emoji
                                const hasTextContent = cleanedText.trim().length > 0;

                                if (!hasTextContent) {
                                    logger.warn(`‚ö†Ô∏è No text content after emoji extraction, skipping message send`);
                                }

                                if (sendMessage && hasTextContent && !isModerationRefusal) {
                                    // R√©cup√©rer les r√©actions appliqu√©es
                                    const appliedEmojis = emojiHandler.getAppliedEmojis();
                                    const reactionEmoji = appliedEmojis.length > 0 ? appliedEmojis[0] : undefined;

                                    // Calculer le temps de r√©ponse total
                                    const responseTime = Date.now() - requestStartTime;

                                    // Tous les messages avec r√©ponse sont stock√©s (le filtrage se fait dans slidingWindowMemory)
                                    const willSaveInMemory = true;

                                    // Logger la r√©ponse de Netricsa avec l'info de m√©moire
                                    await logBotResponse(
                                        userName,
                                        userId,
                                        channelName,
                                        originalUserMessage || prompt, // Utiliser le message original si fourni, sinon le prompt complet
                                        cleanedText,
                                        totalTokens,
                                        imageDescriptions.length > 0,
                                        webContext !== null,
                                        reactionEmoji,
                                        responseTime,
                                        willSaveInMemory
                                    );

                                    if (willSaveInMemory && !skipMemory) {
                                        // Utiliser le message original pour l'analyse du type
                                        const messageToAnalyze = originalUserMessage || prompt;
                                        const messageType = analyzeMessageType(messageToAnalyze);

                                        // D√©tecter si c'est un reply
                                        const isReply = !!replyToMessage?.reference?.messageId;

                                        await memory.appendTurn(
                                            {
                                                ts: Date.now(),
                                                discordUid: userId,
                                                displayName: userName,
                                                channelId: channel.id,
                                                channelName: channelName,
                                                userText: originalUserMessage || prompt, // Utiliser le message original sans contexte
                                                assistantText: cleanedText,
                                                ...(imageDescriptions.length > 0 ? {imageDescriptions: imageDescriptions.slice(0, 5)} : {}),
                                                ...(webContext ? {webContext} : {}),
                                            },
                                            MEMORY_MAX_TURNS
                                        );

                                        const contextInfo = [];
                                        if (imageDescriptions.length > 0) contextInfo.push("images");
                                        if (emojiHandler.getAppliedEmojis().length > 0) contextInfo.push("reactions");
                                        if (messageType.confidence > 0.7) contextInfo.push(`type:${messageType.type}`);
                                        if (isReply) contextInfo.push("reply");

                                        logger.info(`‚úÖ Saved in #${channelName}${contextInfo.length > 0 ? ` [${contextInfo.join(", ")}]` : ""}`);
                                    }

                                    // Enregistrer la conversation IA pour l'utilisateur
                                    recordAIConversationStats(userId, userName);

                                    // Enregistrer la conversation IA pour Netricsa elle-m√™me
                                    recordAIConversationStats(NETRICSA_USER_ID, NETRICSA_USERNAME);

                                    // Ajouter XP avec notification pour l'utilisateur (conversation IA inclut les recherches web)
                                    const {addXP, XP_REWARDS} = require("../services/xpSystem");
                                    await addXP(userId, userName, XP_REWARDS.conversationIA, channel, false);
                                } else if (isModerationRefusal) {
                                    logger.warn(`üö´ Moderation refusal detected, NOT saving to memory`);
                                }

                                // R√©initialiser le statut
                                await clearStatus(client);

                                activeStreams.delete(channelKey);
                                if (throttleResponseInterval) clearInterval(throttleResponseInterval);
                                if (typingInterval) clearInterval(typingInterval);
                                controller.close();

                                // Retirer l'utilisateur de la queue
                                usersInQueue.delete(userId);
                                logger.info(`User ${userId} removed from queue. Current queue size: ${usersInQueue.size}`);

                                // R√©soudre la promesse avec le contenu si demand√©
                                const pending = pendingResponses.get(channelKey);
                                if (pending) {
                                    pending.resolve(cleanedText);
                                    pendingResponses.delete(channelKey);
                                }
                                return;
                            }

                            jsonBuffer += decoder.decode(value, {stream: true});
                            const lines = jsonBuffer.split("\n");
                            jsonBuffer = lines.pop() || "";

                            for (const line of lines) {
                                if (!line.trim()) continue;

                                if (process.env.DEBUG_OLLAMA_RAW === "1") {
                                    logger.info("[Ollama Raw Line]", line);
                                }

                                let decodedChunk: any;
                                try {
                                    decodedChunk = JSON.parse(line);
                                } catch (parseError) {
                                    logger.error("JSON parse error:", parseError);
                                    continue;
                                }

                                const chunk = decodedChunk.message?.delta || decodedChunk.message?.content || "";

                                // D√©tecter les tool calls
                                if (decodedChunk.message?.tool_calls && decodedChunk.message.tool_calls.length > 0) {
                                    toolCalls.push(...decodedChunk.message.tool_calls);
                                    logger.info(`Detected ${decodedChunk.message.tool_calls.length} tool call(s)`);
                                }

                                if (decodedChunk.prompt_eval_count) promptTokens = decodedChunk.prompt_eval_count;
                                if (decodedChunk.eval_count) completionTokens = decodedChunk.eval_count;
                                if (promptTokens && completionTokens) totalTokens = promptTokens + completionTokens;

                                result += chunk;

                                // Pour les interactions, on accumule sans envoyer (pas de streaming)
                                // Pour les messages normaux, on met √† jour les chunks en temps r√©el
                                if (!interaction) {
                                    const cleanedResult = await emojiHandler.extractAndApply(result);
                                    messageManager.addToCurrentChunk(cleanedResult);

                                    // Envoyer le premier message imm√©diatement pour arr√™ter le typing indicator
                                    if (!firstChunkReceived && sendMessage && cleanedResult.trim().length > 0) {
                                        firstChunkReceived = true;
                                        if (loadingTimeout) clearTimeout(loadingTimeout); // Annuler le timeout de chargement
                                        await messageManager.throttleUpdate().catch((err) => logger.error("[FirstChunk] Update error:", err));
                                    }
                                } else {
                                    // Pour les interactions, juste nettoyer le timeout si on re√ßoit le premier chunk
                                    if (!firstChunkReceived) {
                                        firstChunkReceived = true;
                                        if (loadingTimeout) clearTimeout(loadingTimeout);
                                    }
                                }
                            }

                            controller.enqueue(value);
                            return pump();
                        });
                    }
                },
            });
        } catch (error) {
            logger.error("Error processing LLM request:", error);

            // V√©rifier si c'est une erreur de connexion aux services locaux
            const isConnectionError = error instanceof Error && error.message.includes('CONNECTION_ERROR');

            if (isConnectionError) {
                logger.error("üåô Connection error detected - activating Standby Mode");
                // Importer et activer le mode Standby
                const {handleConnectionError} = require('../services/standbyModeService');
                await handleConnectionError(client);
            }

            // Nettoyer le timeout de chargement
            if (loadingTimeout) clearTimeout(loadingTimeout);

            // Retirer l'utilisateur de la queue en cas d'erreur
            usersInQueue.delete(userId);
            logger.info(`User ${userId} removed from queue (error). Current queue size: ${usersInQueue.size}`);

            // Arr√™ter l'indicateur typing
            if (typingInterval) clearInterval(typingInterval);

            // R√©initialiser le statut sp√©cifique en cas d'erreur
            await clearStatus(client, currentStatusId);

            // Rejeter la promesse en cas d'erreur
            const pending = pendingResponses.get(channelKey);
            if (pending) {
                pending.reject(error);
                pendingResponses.delete(channelKey);
            }

            await logError("Erreur de traitement LLM", undefined, [
                {name: "Utilisateur", value: userName, inline: true},
                {name: "Canal", value: (channel as any).name || channel.type === ChannelType.DM ? "DM" : "Thread", inline: true},
                {name: "Erreur", value: error instanceof Error ? error.message : String(error)}
            ]);

            // Message d'erreur adapt√© selon le type d'erreur
            const errorMessage = isConnectionError
                ? "üåô Je ne peux pas me connecter √† l'ordinateur de mon cr√©ateur. Je passe en **mode veille** et v√©rifierai r√©guli√®rement quand il sera de nouveau disponibles."
                : "An error occurred while processing your message.";

            if (replyToMessage) {
                await replyToMessage.reply(errorMessage);
            } else {
                await channel.send(errorMessage);
            }
        }
    });

    // Retourner la promesse si returnResponse est demand√©
    return responsePromise;
}
